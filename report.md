Part C: 比較分析報告
C-1 量化比較

主題	   評估指標	 TF-IDF	 AI
相似度計算	準確率	   60	 90
           處理時間	  7s	10s
	       成本	      $0   Usage: 0.01
文本分類	準確率	   90	 95
	       處理時間	   6s	11s
	       支援類別數  3+5	unlimited
自動摘要	資訊保留度	90    95
	       語句通順度  80	 95
	       長度控制    80	 95

C-2 質性分析報告
在這次文本分析的實作中，比較了兩大類方法：傳統NLP 方法以及現代 AI 方法在文本相似度、文本分類和自動摘要三個領域的表現進行比較和質性分析，並總結實作心得與應用建議。
一、方法特性比較
(一) 傳統方法的優勢與限制
傳統方法的最大優勢在於可解釋性與可控性。例如，規則式情感分類能明確知道「哪些詞」被視為正面或負面，TF-IDF 的相似度也能清楚追蹤每個字詞的權重來源；然而，它的限制在於靈活性不足，對語意、上下文和隱含情緒的理解能力有限。例如，TF-IDF 無法理解「機器學習」和「深度學習」在概念上的高度相關性，只看作是兩個不同的詞彙。
(二) AI方法的優勢與限制
AI 方法則具備語意理解與生成能力。它能處理同義詞、語氣、隱喻等複雜語意，也能自動摘要、分類或評估情感傾向。在相似度比較中，Gemini 能給出更高的分數（如 Doc1 vs Doc4），因為它理解這些都是「人工智慧」範疇的技術。優勢是高準確度與廣泛適用性，能快速應對不同領域的文本任務。不過它的限制在於黑箱特性與依賴性高：結果雖好，但不易理解模型的判斷依據，且需要雲端 API 與穩定的網路與算力支援。
(三) 各自的適用場景
整體而言，傳統方法偏向「可控、透明但笨重」，AI 方法則「靈活、強大但不可解釋」。前者適用於研究、教學與系統原型設計；後者更適合實際應用與需要高語意理解的場景。

二、實作心得
在實作過程中，我首先使用 jieba 進行中文分詞，並建立關鍵字規則來分類主題與情感，基於規則的分類器需要不斷調整正負面詞典、否定詞和程度副詞的權重，是一個耗費人力和經驗的過程。
在使用 Gemini 進行 AI 方法實作時，主要挑戰是輸入與輸出格式控制。例如，模型常輸出包在 json 區塊內的內容，需額外使用正則表達式解析；同時要確保 prompt 設計清楚，模型才會回傳可解析的 JSON 結構。雖然設定了嚴格的 Prompt，但 AI 模型在輸出格式（特別是 JSON）時，偶爾仍需額外的正則表達式清理 (re.sub(r"```json|```", "", ...) )，確保解析成功。
未來我希望進一步學習如何結合 AI 模型與傳統 NLP 特徵工程，例如用 TF-IDF 篩選關鍵句，再交給大型語言模型進行精緻摘要或語意判斷，讓結果兼具精確性與解釋性。
例如RAG (Retrieval-Augmented Generation) 知識增強： 結合傳統的檢索方法（如向量搜尋）來提供準確的領域知識給 LLM，彌補 LLM 容易產生幻覺的缺點。

三、應用建議
(一) 什麼情況下該用傳統方法?
1. 資源受限與高吞吐量需求： 文本相似度、簡單分類和關鍵詞提取等任務，如果需要在低延遲、高頻率、或沒有網路連線的邊緣設備上運行，應首選傳統方法。
2. 高可解釋性要求： 金融、法律、醫療等領域，需要清晰知道決策依據時，基於規則或統計的方法是首選。
3. 數據量極少： 只有數百筆標註數據，難以訓練有效 LLM 時，手動建立規則集更有效。
(二) 什麼情況下該用 AI?
1. 複雜的語義理解與生成： 需要流暢摘要、情感細膩分析、或生成創意文案時。
2. 泛化能力與跨領域應用： 處理多個主題、多種語言，或文本風格變化較大時。
(三) 如何結合兩者的優點?
傳統方法作為預處理層： 使用 TF-IDF 快速過濾和篩選數百萬份文件，將最相關的幾百份文件傳給 LLM。
AI 作為決策或生成層： 利用 LLM 對篩選後的少量文件進行深度閱讀、情感分析、或生成最終報告。
例如，在客服系統中，可以使用 TF-IDF 或關鍵詞匹配來初步分類 90% 的常見問題（快速且免費），將剩下 10% 難以判斷的複雜問題轉交給 LLM 進行精確分類和回覆生成（慢速但準確）。
總結而言，傳統 NLP 方法是堅實的基礎，而現代 AI 方法則是應對複雜性和創造性的利器，兩者並非互相取代，而是相輔相成。